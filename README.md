#	Sorting Algorithms && Big-O


The ```Big-O``` notation, in simple terms shows how the code slows as input grows. It profits to know in the long run how large of an input a code can take before it slows down significantly, thus ```Big-O``` measures in terms of input ```n or N``` the how long the code runs as n gets large.

For example, say a simple code prints a sequence of numbers from 0 to n - 1:
```

The amount of time it would take for the above code to run is dependent on the value of n. If n is < 100, it would ttake less time to run compared to when n is 10 ** 34. This is the time complexity. In ```Big-O``` notation, we say
its time complexity is ```O(n)```. 

- Time Complexity
	- Worst case Scenarios (O)
	- Best case Scenarios (Omega)
	- Average (Theta)
- Best algorithm to use as per trade-offs

## Requirements
- gcc compiler 9.3.0
- Ubuntu 20.04
